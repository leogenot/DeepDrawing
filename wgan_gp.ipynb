{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN-GP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.WGANGP import WGANGP\n",
    "from utils.loaders import load_dataset\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image, create mask, and draw white circle on mask\n",
    "image = cv2.imread('data/dataset128/dataset128/55.png')\n",
    "mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "mask = cv2.circle(mask, (64, 64), 20, (255,255,255), -1) \n",
    "\n",
    "# Mask input image with binary mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "result = cv2.bitwise_and(image, mask)\n",
    "# Color background white\n",
    "result[mask==0] = 255 # Optional\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_path(file_pathname):\n",
    "\n",
    "    # Traverse all the pictures in the folder\n",
    "    for filename in os.listdir(file_pathname):\n",
    "        \n",
    "        print(filename)  # Print picture name\n",
    "        a = 44  # Set the initial edge position of the mask area\n",
    "        img = cv2.imread(file_pathname+'/'+filename)  # Read the picture\n",
    "        # 255： Generate all white numerical matrix （ If you want to generate a black area block ,\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8) \n",
    "        # Need generation 0 matrix .）\n",
    "        # The mask area size is 40×40, Let the pixel value of this area be 0（ black ）\n",
    "        mask[a:a + 40, a:a + 40] = 255\n",
    "        # cv2.bitwise_and It's about binary data “ And ” operation ,\n",
    "        mask = cv2.bitwise_not(mask)\n",
    "        mask_img = cv2.bitwise_and(img, mask)\n",
    "        mask_img[mask==0] = 255\n",
    "        # The white area of the mask image is reserved for the image pixels to be processed , The black area is the elimination of the image pixels to be processed\n",
    "        # Save the image to the specified location\n",
    "        cv2.imwrite(\"/Users/leogenot/Desktop/DeepDrawingGeneration-WGAN-GP/data/dataset128masked/\"+filename, mask_img)\n",
    "read_path(\"/Users/leogenot/Desktop/DeepDrawingGeneration-WGAN-GP/data/dataset128tomask/dataset128\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'dataset128'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_dataset(DATA_NAME, IMAGE_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = WGANGP(input_dim = (IMAGE_SIZE,IMAGE_SIZE,1)\n",
    "        , critic_conv_filters = [128,256,512,1024]\n",
    "        , critic_conv_kernel_size = [5,5,5,5]\n",
    "        , critic_conv_strides = [2,2,2,2]\n",
    "        , critic_batch_norm_momentum = None\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = None\n",
    "        , critic_learning_rate = 0.0002\n",
    "        , generator_initial_dense_layer_size = (8, 8, 512)\n",
    "        , generator_upsample = [1,1,1,1]\n",
    "        , generator_conv_filters = [512,256,128,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [2,2,2,2]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0002\n",
    "        , optimiser = 'adam'\n",
    "        , grad_weight = 10\n",
    "        , z_dim = 100\n",
    "        , batch_size = BATCH_SIZE\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6501\n",
    "PRINT_EVERY_N_BATCHES = 500\n",
    "N_CRITIC = 5\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    "    , using_generator = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make gif of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "\n",
    "out_file = 'generated_data.gif'\n",
    "\n",
    "with imageio.get_writer(out_file, mode='I', duration=0.3) as writer:\n",
    "    file_names = glob.glob(os.path.join(RUN_FOLDER, 'images') + '/*.png')\n",
    "    file_names = sorted(file_names)\n",
    "    last = -1\n",
    "\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        animated_image = imageio.imread(file_name)\n",
    "        writer.append_data(animated_image)\n",
    "\n",
    "    animated_image = imageio.imread(file_name)\n",
    "    writer.append_data(animated_image)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(open('generated_data.gif','rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = tf.keras.models.load_model( \"run/gan/0003_dataset64/model.h5\", compile = False )\n",
    "loaded_model.predict(\"data/dataset64/dataset64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-24 12:19:07.836365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of loading the generator model and generating images\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input\n",
    "\n",
    "# plot the generated images\n",
    "def create_plot(examples, n):\n",
    "\t# plot images\n",
    "\tfor i in range(n * n):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(n, n, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(examples[i, :], cmap=\"gray\")\n",
    "  \t\t##pyplot.imshow(examples[i, :], cmap=\"gray\")\n",
    "  \t\t\n",
    "\tpyplot.show()\n",
    "\n",
    "# load model\n",
    "model = load_model(\"run/gan/0003_dataset64/generator.h5\")\n",
    "# generate images\n",
    "latent_points = generate_latent_points(100, 100)\n",
    "# generate images\n",
    "X = model.predict(latent_points)\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "create_plot(X, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd49c10cbc72fbd46a21231d9303b5a70a75ba44a759e796425aabfbc9279761"
  },
  "kernelspec": {
   "display_name": "gdl_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
