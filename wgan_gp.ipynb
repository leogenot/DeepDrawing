{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN-GP Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from utils.loaders import load_dataset\n",
    "from models.WGANGP import WGANGP\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image, create mask, and draw white circle on mask\n",
    "image = cv2.imread('data/dataset128/dataset128/55.png')\n",
    "mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "mask = cv2.circle(mask, (64, 64), 20, (255,255,255), -1) \n",
    "\n",
    "# Mask input image with binary mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "result = cv2.bitwise_and(image, mask)\n",
    "# Color background white\n",
    "result[mask==0] = 255 # Optional\n",
    "\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('result', result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_path(file_pathname):\n",
    "\n",
    "    # Traverse all the pictures in the folder\n",
    "    for filename in os.listdir(file_pathname):\n",
    "        \n",
    "        print(filename)  # Print picture name\n",
    "        a = 44  # Set the initial edge position of the mask area\n",
    "        img = cv2.imread(file_pathname+'/'+filename)  # Read the picture\n",
    "        # 255： Generate all white numerical matrix （ If you want to generate a black area block ,\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8) \n",
    "        # Need generation 0 matrix .）\n",
    "        # The mask area size is 40×40, Let the pixel value of this area be 0（ black ）\n",
    "        mask[a:a + 40, a:a + 40] = 255\n",
    "        # cv2.bitwise_and It's about binary data “ And ” operation ,\n",
    "        mask = cv2.bitwise_not(mask)\n",
    "        mask_img = cv2.bitwise_and(img, mask)\n",
    "        mask_img[mask==0] = 255\n",
    "        # The white area of the mask image is reserved for the image pixels to be processed , The black area is the elimination of the image pixels to be processed\n",
    "        # Save the image to the specified location\n",
    "        cv2.imwrite(\"/Users/leogenot/Desktop/DeepDrawingGeneration-WGAN-GP/data/dataset128masked/\"+filename, mask_img)\n",
    "read_path(\"/Users/leogenot/Desktop/DeepDrawingGeneration-WGAN-GP/data/dataset128tomask/dataset128\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'dataset128'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode = 'build'  # 'load' #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_dataset(DATA_NAME, IMAGE_SIZE, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x_train[0][0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = WGANGP(input_dim=(IMAGE_SIZE, IMAGE_SIZE, 1), critic_conv_filters=[128, 256, 512, 1024], critic_conv_kernel_size=[5, 5, 5, 5], critic_conv_strides=[2, 2, 2, 2], critic_batch_norm_momentum=None, critic_activation='leaky_relu', critic_dropout_rate=None, critic_learning_rate=0.0002, generator_initial_dense_layer_size=(8, 8, 512), generator_upsample=[1, 1, 1, 1], generator_conv_filters=[512, 256, 128, 1], generator_conv_kernel_size=[5, 5, 5, 5], generator_conv_strides=[2, 2, 2, 2], generator_batch_norm_momentum=0.9, generator_activation='leaky_relu', generator_dropout_rate=None, generator_learning_rate=0.0002, optimiser='adam', grad_weight=10, z_dim=100, batch_size=BATCH_SIZE\n",
    "             )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.critic.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6501\n",
    "PRINT_EVERY_N_BATCHES = 500\n",
    "N_CRITIC = 5\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(\n",
    "    x_train, batch_size=BATCH_SIZE, epochs=EPOCHS, run_folder=RUN_FOLDER, print_every_n_batches=PRINT_EVERY_N_BATCHES, n_critic=N_CRITIC, using_generator=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make gif of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "out_file = 'generated_data.gif'\n",
    "\n",
    "with imageio.get_writer(out_file, mode='I', duration=0.3) as writer:\n",
    "    file_names = glob.glob(os.path.join(RUN_FOLDER, 'images') + '/*.png')\n",
    "    file_names = sorted(file_names)\n",
    "    last = -1\n",
    "\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        animated_image = imageio.imread(file_name)\n",
    "        writer.append_data(animated_image)\n",
    "\n",
    "    animated_image = imageio.imread(file_name)\n",
    "    writer.append_data(animated_image)\n",
    "\n",
    "Image(open('generated_data.gif', 'rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the generator model and generating images\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy.random import randn\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# plot the generated images\n",
    "\n",
    "\n",
    "def create_plot(examples, n):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :], cmap=\"gray\")\n",
    "        ##pyplot.imshow(examples[i, :], cmap=\"gray\")\n",
    "\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# load model\n",
    "model = load_model(\"generator.h5\")\n",
    "# generate images\n",
    "latent_points = generate_latent_points(100, 1)\n",
    "# generate images\n",
    "X = model.predict(latent_points)\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "create_plot(X, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 1 latent space images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of interpolating between generated faces\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import linspace\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from matplotlib.pyplot import imsave\n",
    "from matplotlib.pyplot import cm\n",
    "import io\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return z_input\n",
    "\n",
    "# uniform interpolation between two points in latent space\n",
    "\n",
    "\n",
    "def interpolate_points(p1, p2, n_steps=10):\n",
    "    # interpolate ratios between the points\n",
    "    ratios = linspace(0, 1, num=n_steps)\n",
    "    # linear interpolate vectors\n",
    "    vectors = list()\n",
    "    for ratio in ratios:\n",
    "        v = (1.0 - ratio) * p1 + ratio * p2\n",
    "        vectors.append(v)\n",
    "    return asarray(vectors)\n",
    "\n",
    "# create a plot of generated images\n",
    "size = 128\n",
    "\n",
    "def plot_generated(examples, n):\n",
    "    # plot images\n",
    "        \n",
    "        \n",
    "        r, c = 5, 5\n",
    "        fig, axs = pyplot.subplots(r, c, figsize=(15,15))\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(np.squeeze(examples[i, :,:,:]), cmap = 'gray_r')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(\"images2/sample_%d.png\" % i))\n",
    "        #pyplot.close()\n",
    "\n",
    "# load model\n",
    "model = load_model('generator.h5')\n",
    "for k in range(10):\n",
    "    # generate points in latent space\n",
    "    pts = generate_latent_points(100, 2)\n",
    "    print(pts.shape)\n",
    "    # interpolate points in latent space\n",
    "    interpolated = interpolate_points(pts[0], pts[1])\n",
    "    # generate images\n",
    "    X = model.predict(interpolated)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot the result\n",
    "    plot_generated(X, len(interpolated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate grid latent space images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the generator model and generating images\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn z_input\n",
    "\n",
    "# create a plot of generated images\n",
    "def plot_generated(examples, n):\n",
    "\t# plot images\n",
    "\tfor i in range(n * n):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(n, n, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(examples[i, :, :])\n",
    "\tpyplot.show()\n",
    "\n",
    "# load model\n",
    "model = load_model('generator.h5')\n",
    "# generate images\n",
    "latent_points = generate_latent_points(100, 25)\n",
    "# generate images\n",
    "X  = model.predict(latent_points)\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "plot_generated(X, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphBetweenImages(model, num_of_morphs, latent_space_size):\n",
    "    # define alpha \n",
    "    alpha = np.linspace(0,1,num_of_morphs)\n",
    "    # get latent spaces\n",
    "    z1 = np.random.normal(0, 1, size=(1, latent_space_size))\n",
    "    z2 = np.random.normal(0, 1, size=(1, latent_space_size))\n",
    "    # morph and plot\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    for i in range(num_of_morphs):\n",
    "        z = z1*(1-alpha[i]) + z2*alpha[i]\n",
    "        new_img = model.predict(z)\n",
    "        # rescale images\n",
    "        new_img = 0.5 * (new_img + 1)\n",
    "        new_img = np.clip(new_img, 0, 1)\n",
    "        ax = fig.add_subplot(1, num_of_morphs, i+1)\n",
    "        ax.imshow(new_img.squeeze())\n",
    "        ax.axis('off')\n",
    "        ax.set_title(loc='center', label='alpha={:.2f}'.format(alpha[i]))\n",
    "    return\n",
    "\n",
    "model = load_model('generator.h5')\n",
    "num_of_morphs = 12\n",
    "morphBetweenImages(model, num_of_morphs, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create morph video of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import cv2\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "im_sz = 1024\n",
    "mp_sz = 96\n",
    "\n",
    "warp_scale = 0.05\n",
    "mult_scale = 0.4\n",
    "add_scale = 0.4\n",
    "add_first = False\n",
    "def warp(origins, targets, preds_org, preds_trg):\n",
    "    if add_first:\n",
    "        res_targets = tfa.image.dense_image_warp((origins + preds_org[:,:,:,3:6] * 2 * add_scale) * tf.maximum(0.1, 1 + preds_org[:,:,:,0:3] * mult_scale) , preds_org[:,:,:,6:8] * im_sz * warp_scale )        \n",
    "        res_origins = tfa.image.dense_image_warp((targets + preds_trg[:,:,:,3:6] * 2 * add_scale) * tf.maximum(0.1, 1 + preds_trg[:,:,:,0:3] * mult_scale) , preds_trg[:,:,:,6:8] * im_sz * warp_scale )\n",
    "    else:\n",
    "        res_targets = tfa.image.dense_image_warp(origins * tf.maximum(0.1, 1 + preds_org[:,:,:,0:3] * mult_scale) + preds_org[:,:,:,3:6] * 2 * add_scale, preds_org[:,:,:,6:8] * im_sz * warp_scale )        \n",
    "        res_origins = tfa.image.dense_image_warp(targets * tf.maximum(0.1, 1 + preds_trg[:,:,:,0:3] * mult_scale) + preds_trg[:,:,:,3:6] * 2 * add_scale, preds_trg[:,:,:,6:8] * im_sz * warp_scale )\n",
    "\n",
    "    return res_targets, res_origins\n",
    "\n",
    "\n",
    "def use_warp_maps(origins, targets, fps, steps):\n",
    "    STEPS = steps\n",
    "    \n",
    "    preds = np.load('preds.npy')\n",
    "    \n",
    "    #save maps as images\n",
    "    res_img = np.zeros((im_sz * 2, im_sz * 3, 3))\n",
    "\n",
    "    res_img[im_sz*0:im_sz*1, im_sz*0:im_sz*1] = preds[0,:,:,0:3] # a_to_b add map\n",
    "    res_img[im_sz*0:im_sz*1, im_sz*1:im_sz*2] = preds[0,:,:,3:6] # a_to_b mult map\n",
    "    res_img[im_sz*0:im_sz*1, im_sz*2:im_sz*3, :2] = preds[0,:,:,6:8] # a_to_b warp map\n",
    "    \n",
    "    res_img[im_sz*1:im_sz*2, im_sz*0:im_sz*1] = preds[0,:,:,8:11] # b_to_a add map\n",
    "    res_img[im_sz*1:im_sz*2, im_sz*1:im_sz*2] = preds[0,:,:,11:14] # b_to_a mult map\n",
    "    res_img[im_sz*1:im_sz*2, im_sz*2:im_sz*3, :2] = preds[0,:,:,14:16] # b_to_a warp map\n",
    "    \n",
    "    res_img = np.clip(res_img, -1, 1)\n",
    "    res_img = ((res_img + 1) * 127.5).astype(np.uint8)\n",
    "    cv2.imwrite(\"morph/maps.jpg\", cv2.cvtColor(res_img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    \n",
    "    #apply maps and save results\n",
    "    \n",
    "    org_strength = tf.reshape(tf.range(STEPS, dtype=tf.float32), [STEPS, 1, 1, 1]) / (STEPS - 1) \n",
    "    trg_strength = tf.reverse(org_strength, axis = [0])\n",
    " \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter('morph/morph.mp4', fourcc, fps, (im_sz, im_sz))\n",
    "    img_a = np.zeros((im_sz, im_sz * (STEPS // 10), 3), dtype = np.uint8)\n",
    "    img_b = np.zeros((im_sz, im_sz * (STEPS // 10), 3), dtype = np.uint8)\n",
    "    img_a_b = np.zeros((im_sz, im_sz * (STEPS // 10), 3), dtype = np.uint8)\n",
    "    \n",
    "    res_img = np.zeros((im_sz * 3, im_sz * (STEPS // 10), 3), dtype = np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(STEPS)):\n",
    "        preds_org = preds * org_strength[i]\n",
    "        preds_trg = preds * trg_strength[i]\n",
    "    \n",
    "        res_targets, res_origins = warp(origins, targets, preds_org[...,:8], preds_trg[...,8:])\n",
    "        res_targets = tf.clip_by_value(res_targets, -1, 1)\n",
    "        res_origins = tf.clip_by_value(res_origins, -1, 1)\n",
    "        \n",
    "        results = res_targets * trg_strength[i] + res_origins * org_strength[i]\n",
    "        res_numpy = results.numpy()\n",
    "    \n",
    "        img = ((res_numpy[0] + 1) * 127.5).astype(np.uint8)\n",
    "        video.write(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        if (i+1) % 10 == 0: \n",
    "            res_img[im_sz*0:im_sz*1, i // 10 * im_sz : (i // 10 + 1) * im_sz] = img\n",
    "            res_img[im_sz*1:im_sz*2, i // 10 * im_sz : (i // 10 + 1) * im_sz] = ((res_targets.numpy()[0] + 1) * 127.5).astype(np.uint8)\n",
    "            res_img[im_sz*2:im_sz*3, i // 10 * im_sz : (i // 10 + 1) * im_sz] = ((res_origins.numpy()[0] + 1) * 127.5).astype(np.uint8)\n",
    "            \n",
    "    cv2.imwrite(\"morph/result.jpg\", cv2.cvtColor(res_img, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()   \n",
    "    print ('Result video saved.') \n",
    "    \n",
    " \n",
    "dom_a = cv2.imread(\"images/imageg_9999.png\", cv2.IMREAD_COLOR)\n",
    "dom_a = cv2.cvtColor(dom_a, cv2.COLOR_BGR2RGB)\n",
    "dom_a = cv2.resize(dom_a, (im_sz, im_sz), interpolation = cv2.INTER_AREA)\n",
    "dom_a = dom_a / 127.5 - 1\n",
    "\n",
    "dom_b = cv2.imread(\"images/imageg_0.png\", cv2.IMREAD_COLOR)\n",
    "dom_b = cv2.cvtColor(dom_b, cv2.COLOR_BGR2RGB)\n",
    "dom_b = cv2.resize(dom_b, (im_sz, im_sz), interpolation = cv2.INTER_AREA)\n",
    "dom_b = dom_b / 127.5 - 1\n",
    "\n",
    "origins = dom_a.reshape(1, im_sz, im_sz, 3).astype(np.float32)\n",
    "targets = dom_b.reshape(1, im_sz, im_sz, 3).astype(np.float32)\n",
    "use_warp_maps(origins, targets, 18, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd49c10cbc72fbd46a21231d9303b5a70a75ba44a759e796425aabfbc9279761"
  },
  "kernelspec": {
   "display_name": "gdl_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
